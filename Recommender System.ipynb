{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import permutations\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import KFold\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "movie = pd.read_csv('movies.csv')\n",
    "rating = pd.read_csv('user_ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Pair Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   movie_a                           movie_b\n",
      "0         Toy Story (1995)           Grumpier Old Men (1995)\n",
      "1         Toy Story (1995)                       Heat (1995)\n",
      "2         Toy Story (1995)       Seven (a.k.a. Se7en) (1995)\n",
      "3         Toy Story (1995)        Usual Suspects, The (1995)\n",
      "4         Toy Story (1995)        From Dusk Till Dawn (1996)\n",
      "...                    ...                               ...\n",
      "60793295         31 (2016)                 Gen-X Cops (1999)\n",
      "60793296         31 (2016)                  Bloodmoon (1997)\n",
      "60793297         31 (2016)  Sympathy for the Underdog (1971)\n",
      "60793298         31 (2016)                     Hazard (2005)\n",
      "60793299         31 (2016)                Blair Witch (2016)\n",
      "\n",
      "[60793300 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find all permutations\n",
    "def find_pair(x):\n",
    "    pair = pd.DataFrame(list(permutations(x.values, 2)), columns=['movie_a', 'movie_b'])\n",
    "    return pair\n",
    "\n",
    "# Permute the title column and reset the index\n",
    "movie_combo = rating.groupby('userId')['title'].apply(find_pair).reset_index(drop=True)\n",
    "print(movie_combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            movie_a  \\\n",
      "0                                        '71 (2014)   \n",
      "1                                        '71 (2014)   \n",
      "2                                        '71 (2014)   \n",
      "3                                        '71 (2014)   \n",
      "4                                        '71 (2014)   \n",
      "...                                             ...   \n",
      "26309176  À nous la liberté (Freedom for Us) (1931)   \n",
      "26309177  À nous la liberté (Freedom for Us) (1931)   \n",
      "26309178  À nous la liberté (Freedom for Us) (1931)   \n",
      "26309179  À nous la liberté (Freedom for Us) (1931)   \n",
      "26309180  À nous la liberté (Freedom for Us) (1931)   \n",
      "\n",
      "                                             movie_b  count  \n",
      "0                        (500) Days of Summer (2009)      1  \n",
      "1                         10 Cloverfield Lane (2016)      1  \n",
      "2                                   127 Hours (2010)      1  \n",
      "3         13 Assassins (Jûsan-nin no shikaku) (2010)      1  \n",
      "4                                    13 Hours (2016)      1  \n",
      "...                                              ...    ...  \n",
      "26309176                               Willow (1988)      1  \n",
      "26309177  Willy Wonka & the Chocolate Factory (1971)      1  \n",
      "26309178                    Wizard of Oz, The (1939)      1  \n",
      "26309179         World According to Garp, The (1982)      1  \n",
      "26309180       X-Files: Fight the Future, The (1998)      1  \n",
      "\n",
      "[26309181 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the frequency of movie_a occurance with movie_b\n",
    "combo_count = movie_combo.groupby(['movie_a', 'movie_b']).size()\n",
    "# Convert to a DataFrame and reset the index\n",
    "combo_count_df = combo_count.to_frame(name='count').reset_index()\n",
    "print(combo_count_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_a</th>\n",
       "      <th>movie_b</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24019673</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Forrest Gump (1994)</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24023000</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24023672</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24024033</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Star Wars: Episode IV - A New Hope (1977)</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24021020</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Jurassic Park (1993)</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   movie_a                                    movie_b  count\n",
       "24019673  Toy Story (1995)                        Forrest Gump (1994)    154\n",
       "24023000  Toy Story (1995)                        Pulp Fiction (1994)    141\n",
       "24023672  Toy Story (1995)           Shawshank Redemption, The (1994)    137\n",
       "24024033  Toy Story (1995)  Star Wars: Episode IV - A New Hope (1977)    134\n",
       "24021020  Toy Story (1995)                       Jurassic Park (1993)    132"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the combination counts descendingly\n",
    "combo_count_df = combo_count_df.sort_values('count', ascending=False)\n",
    "# Find the 5 movies most watched by users who watched Toy Story (1995)\n",
    "combo_count_df[combo_count_df.movie_a == 'Toy Story (1995)'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert genres string to list with top 3 elements\n",
    "def str_list(x):\n",
    "    return x.split(\"|\")[:3]\n",
    "\n",
    "movie['genres'] = movie.genres.apply(str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings to lower case\n",
    "def to_low(x):\n",
    "    return [str.lower(i) for i in x]\n",
    "\n",
    "movie['genres'] = movie.genres.apply(to_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metadata soup\n",
    "movie['soup'] = movie.genres.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the count matrix\n",
    "count = CountVectorizer(stop_words = 'english')\n",
    "count_matrix = count.fit_transform(movie.soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Cosine Similarity\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A reverse map of indices and movie titles\n",
    "indices = pd.Series(movie.index, index=movie.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in movie title as input and outputs most similar movies\n",
    "def recommend(title):\n",
    "    # The index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "    # The pairwsie similarity scores of all movies\n",
    "    scores = list(enumerate(cosine_sim[idx]))\n",
    "    # Sort the movies based on the similarity scores\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    # The scores of the 10 most similar movies\n",
    "    top_10 = scores[1:11]\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in top_10]\n",
    "    # Return the top 10 most similar movies\n",
    "    return movie['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12                                          Balto (1995)\n",
       "322                                Lion King, The (1994)\n",
       "506                                       Aladdin (1992)\n",
       "534                       All Dogs Go to Heaven 2 (1996)\n",
       "551                     James and the Giant Peach (1996)\n",
       "559                                     Space Jam (1996)\n",
       "578                              Oliver & Company (1988)\n",
       "673    Land Before Time III: The Time of the Great Gi...\n",
       "787                                 Pete's Dragon (1977)\n",
       "789                           Alice in Wonderland (1951)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recommend movies to people who watched Toy Story (1995)\n",
    "recommend('Toy Story (1995)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53                     Indian in the Cupboard, The (1995)\n",
       "109                     NeverEnding Story III, The (1994)\n",
       "701                              Wizard of Oz, The (1939)\n",
       "767                       Escape to Witch Mountain (1975)\n",
       "1514            Darby O'Gill and the Little People (1959)\n",
       "1556                                  Return to Oz (1985)\n",
       "1565                                     Tall Tale (1995)\n",
       "1617                        NeverEnding Story, The (1984)\n",
       "1618    NeverEnding Story II: The Next Chapter, The (1...\n",
       "1799                        Santa Claus: The Movie (1985)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recommend movies to people who watched Jumanji (1995)\n",
    "recommend('Jumanji (1995)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x7f9d76f622d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate reader\n",
    "reader = Reader()\n",
    "# Load dataset into a form that SVD accepts\n",
    "data = Dataset.load_from_df(rating[['userId', 'movieId', 'rating']], reader)\n",
    "# Perform K-Fold with 5 folds on the rating dataset\n",
    "kf = KFold(n_splits=5)\n",
    "# Split the dataset\n",
    "kf.split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8842  0.8713  0.8640  0.8707  0.8753  0.8731  0.0066  \n",
      "MAE (testset)     0.6804  0.6692  0.6648  0.6669  0.6710  0.6704  0.0054  \n",
      "Fit time          6.41    6.97    6.88    7.36    6.46    6.82    0.35    \n",
      "Test time         0.37    0.23    0.56    0.24    0.28    0.34    0.12    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.88415071, 0.87133706, 0.86399262, 0.87072034, 0.87534694]),\n",
       " 'test_mae': array([0.68036011, 0.66915498, 0.66480937, 0.66685506, 0.67103677]),\n",
       " 'fit_time': (6.410394906997681,\n",
       "  6.969261884689331,\n",
       "  6.882070064544678,\n",
       "  7.362034797668457,\n",
       "  6.455087184906006),\n",
       " 'test_time': (0.3685901165008545,\n",
       "  0.23425912857055664,\n",
       "  0.5576927661895752,\n",
       "  0.2388608455657959,\n",
       "  0.2785799503326416)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate SVD model\n",
    "svd = SVD()\n",
    "# Perform cross validation with the loss metrics of RMSE\n",
    "cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=1, iid=302, r_ui=3, est=4.0151160072345835, details={'was_impossible': False})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on the dataset and predict\n",
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)\n",
    "svd.predict(1, 302, 3)",
    "# It is estiamted that the user with ID 1 will rate 4.02 on movie with ID 302."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "view = rating[['userId', 'movieId']].copy()\n",
    "# Convert movieId from integer to string\n",
    "view['movieId'] = view.movieId.astype(str)\n",
    "# Group movies per user\n",
    "view['movie'] = view.groupby(\"userId\")['movieId'].transform(lambda x: ','.join(x))\n",
    "# Drop movieId column\n",
    "view = view.drop('movieId', axis=1)\n",
    "# Drop duplicated user column\n",
    "view = view.drop_duplicates(subset='userId')\n",
    "# Sort and set user as index\n",
    "view = view.sort_values('userId').set_index('userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split transaction strings into lists\n",
    "view = view.movie.apply(lambda t: t.split(','))\n",
    "# Convert Dataframe into list of strings\n",
    "view = list(view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate movie view encoder\n",
    "encoder = TransactionEncoder()\n",
    "# One-hot encode itemsets by applying fit and transform\n",
    "onehot = encoder.fit(view).transform(view)\n",
    "# Convert one-hot encoded data to DataFrame\n",
    "onehot = pd.DataFrame(onehot, columns=encoder.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352459</td>\n",
       "      <td>(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.216393</td>\n",
       "      <td>(10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.116393</td>\n",
       "      <td>(1028)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104918</td>\n",
       "      <td>(1035)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.237705</td>\n",
       "      <td>(1036)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5384</th>\n",
       "      <td>0.111475</td>\n",
       "      <td>(8961, 858)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385</th>\n",
       "      <td>0.101639</td>\n",
       "      <td>(904, 858)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5386</th>\n",
       "      <td>0.118033</td>\n",
       "      <td>(912, 858)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>0.114754</td>\n",
       "      <td>(858, 924)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>0.106557</td>\n",
       "      <td>(8961, 8636)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5389 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       support      itemsets\n",
       "0     0.352459           (1)\n",
       "1     0.216393          (10)\n",
       "2     0.116393        (1028)\n",
       "3     0.104918        (1035)\n",
       "4     0.237705        (1036)\n",
       "...        ...           ...\n",
       "5384  0.111475   (8961, 858)\n",
       "5385  0.101639    (904, 858)\n",
       "5386  0.118033    (912, 858)\n",
       "5387  0.114754    (858, 924)\n",
       "5388  0.106557  (8961, 8636)\n",
       "\n",
       "[5389 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute frequent itemsets using the Apriori algorithm\n",
    "freqent_itemsets = apriori(onehot, min_support=0.1,\n",
    "                           use_colnames=True, max_len=2)\n",
    "freqent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3114)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.159016</td>\n",
       "      <td>0.352459</td>\n",
       "      <td>0.132787</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>2.369216</td>\n",
       "      <td>0.076740</td>\n",
       "      <td>3.925717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(788)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.134426</td>\n",
       "      <td>0.352459</td>\n",
       "      <td>0.109836</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>2.318208</td>\n",
       "      <td>0.062456</td>\n",
       "      <td>3.539891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10)</td>\n",
       "      <td>(356)</td>\n",
       "      <td>0.216393</td>\n",
       "      <td>0.539344</td>\n",
       "      <td>0.178689</td>\n",
       "      <td>0.825758</td>\n",
       "      <td>1.531040</td>\n",
       "      <td>0.061978</td>\n",
       "      <td>2.643763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1028)</td>\n",
       "      <td>(356)</td>\n",
       "      <td>0.116393</td>\n",
       "      <td>0.539344</td>\n",
       "      <td>0.101639</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>1.619076</td>\n",
       "      <td>0.038863</td>\n",
       "      <td>3.634062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1370)</td>\n",
       "      <td>(1036)</td>\n",
       "      <td>0.111475</td>\n",
       "      <td>0.237705</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>3.773834</td>\n",
       "      <td>0.073502</td>\n",
       "      <td>7.405152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>(736)</td>\n",
       "      <td>(780)</td>\n",
       "      <td>0.201639</td>\n",
       "      <td>0.331148</td>\n",
       "      <td>0.162295</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>2.430572</td>\n",
       "      <td>0.095523</td>\n",
       "      <td>3.427869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>(788)</td>\n",
       "      <td>(780)</td>\n",
       "      <td>0.134426</td>\n",
       "      <td>0.331148</td>\n",
       "      <td>0.111475</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>2.504226</td>\n",
       "      <td>0.066960</td>\n",
       "      <td>3.917564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>(91529)</td>\n",
       "      <td>(79132)</td>\n",
       "      <td>0.124590</td>\n",
       "      <td>0.234426</td>\n",
       "      <td>0.109836</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>3.760582</td>\n",
       "      <td>0.080629</td>\n",
       "      <td>6.464845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>(99114)</td>\n",
       "      <td>(79132)</td>\n",
       "      <td>0.116393</td>\n",
       "      <td>0.234426</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.859155</td>\n",
       "      <td>3.664927</td>\n",
       "      <td>0.072714</td>\n",
       "      <td>5.435574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>(8636)</td>\n",
       "      <td>(8961)</td>\n",
       "      <td>0.129508</td>\n",
       "      <td>0.204918</td>\n",
       "      <td>0.106557</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>4.015190</td>\n",
       "      <td>0.080019</td>\n",
       "      <td>4.486534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    antecedents consequents  antecedent support  consequent support   support  \\\n",
       "0        (3114)         (1)            0.159016            0.352459  0.132787   \n",
       "1         (788)         (1)            0.134426            0.352459  0.109836   \n",
       "2          (10)       (356)            0.216393            0.539344  0.178689   \n",
       "3        (1028)       (356)            0.116393            0.539344  0.101639   \n",
       "4        (1370)      (1036)            0.111475            0.237705  0.100000   \n",
       "..          ...         ...                 ...                 ...       ...   \n",
       "383       (736)       (780)            0.201639            0.331148  0.162295   \n",
       "384       (788)       (780)            0.134426            0.331148  0.111475   \n",
       "385     (91529)     (79132)            0.124590            0.234426  0.109836   \n",
       "386     (99114)     (79132)            0.116393            0.234426  0.100000   \n",
       "387      (8636)      (8961)            0.129508            0.204918  0.106557   \n",
       "\n",
       "     confidence      lift  leverage  conviction  \n",
       "0      0.835052  2.369216  0.076740    3.925717  \n",
       "1      0.817073  2.318208  0.062456    3.539891  \n",
       "2      0.825758  1.531040  0.061978    2.643763  \n",
       "3      0.873239  1.619076  0.038863    3.634062  \n",
       "4      0.897059  3.773834  0.073502    7.405152  \n",
       "..          ...       ...       ...         ...  \n",
       "383    0.804878  2.430572  0.095523    3.427869  \n",
       "384    0.829268  2.504226  0.066960    3.917564  \n",
       "385    0.881579  3.760582  0.080629    6.464845  \n",
       "386    0.859155  3.664927  0.072714    5.435574  \n",
       "387    0.822785  4.015190  0.080019    4.486534  \n",
       "\n",
       "[388 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute all association rules for frequent_itemsets\n",
    "# Choose 80% minimum confidence value. In other words, \n",
    "# when movie X is viewed, we can say that the purchase of product Y is 80% or more.\n",
    "rules = association_rules(freqent_itemsets,\n",
    "                          metric=\"confidence\",\n",
    "                          min_threshold=0.8)\n",
    "rules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
